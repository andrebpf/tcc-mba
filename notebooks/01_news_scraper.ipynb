{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Scraper - InfoMoney (Processamento em Lote)\n",
    "\n",
    "Este notebook utiliza o módulo `src.scraper` para coletar notícias do InfoMoney via API.\n",
    "Ele itera sobre uma lista de termos de pesquisa, salva arquivos CSV individuais e, em seguida, os consolida em um único dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Fix para erro de Unicode no Windows\n",
    "os.environ[\"PYTHONUTF8\"] = \"1\"\n",
    "\n",
    "# Auto-reload para refletir mudanças nos scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Add root directory to path to import src modules\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src.scraper import get_news_from_period\n",
    "from src.utils.logger import setup_logger\n",
    "\n",
    "# Configure logger to see output in the notebook\n",
    "logger = setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição de Parâmetros\n",
    "Defina a lista de termos de pesquisa, a data de início da coleta e a pasta de saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurado para buscar 10 termos entre 2025-01-01 e 2025-12-31\n",
      "Resultados serão salvos em: d:\\dev\\mba-tcc\\src\\dataset\\scraper\\search\n"
     ]
    }
   ],
   "source": [
    "SEARCH_TERMS = [\"Itaú\", \"Dólar\", \"Petrobras\", \"Vale\", \"Bolsa de Valores\", \"Bolsa\", \"B3\", \"IBOVESPA\", \"Bradesco\", \"Economia\"]\n",
    "START_DATE = datetime(2025, 1, 1)\n",
    "END_DATE = datetime(2025, 12, 31)\n",
    "OUTPUT_DIR = os.path.join(\"..\", \"src\", \"dataset\", \"scraper\", \"search\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Configurado para buscar {len(SEARCH_TERMS)} termos entre {START_DATE.date()} e {END_DATE.date()}\")\n",
    "print(f\"Resultados serão salvos em: {os.path.abspath(OUTPUT_DIR)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execução da Coleta em Lote\n",
    "Itera pelos termos, coleta dados e salva em CSV na pasta de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in SEARCH_TERMS:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processando termo: '{term}'\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    try:\n",
    "        # Execute scraper for the current term\n",
    "        df = get_news_from_period(term=term, start_date=START_DATE, end_date=END_DATE)\n",
    "        \n",
    "        if not df.empty:\n",
    "            # Generate filename\n",
    "            safe_term = term.replace(\" \", \"_\").lower()\n",
    "            timestamp = datetime.now().strftime('%Y%m%d')\n",
    "            filename = f\"news_{safe_term}_{timestamp}.csv\"\n",
    "            filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "            \n",
    "            # Save to CSV\n",
    "            df.to_csv(filepath, index=False)\n",
    "            print(f\"\\n[SUCESSO] Salvas {len(df)} notícias para '{term}' em: {filepath}\")\n",
    "            \n",
    "            # Optional: Display first few rows\n",
    "            display(df.head(3))\n",
    "        else:\n",
    "            print(f\"\\n[AVISO] Nenhuma notícia encontrada para '{term}'\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n[ERRO] Falha ao coletar termo '{term}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidar Resultados\n",
    "Lê todos os arquivos CSV da pasta de resultados, combina-os em um único dataset e remove duplicatas (com base no link)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Iniciando Consolidação e Filtragem...\n",
      "==================================================\n",
      "Encontrados 10 arquivos para consolidar.\n",
      "Total de linhas antes da desduplicação e filtragem: 32538\n",
      "Total únicos após desduplicação: 16234\n",
      "\n",
      "Aplicando filtro com 30 palavras-chave...\n",
      "Total de notícias após filtragem: 5909\n",
      "Notícias removidas: 10325\n",
      "\n",
      "[SUCESSO] Arquivo consolidado e filtrado salvo em: ..\\src\\dataset\\scraper\\consolidated_news_20260209.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>2025-12-30 19:14:13</td>\n",
       "      <td>Ouro fecha ano com alta de 65,24%; Ibovespa é ...</td>\n",
       "      <td>https://www.infomoney.com.br/mercados/ouro-fec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-12-30 19:03:37</td>\n",
       "      <td>O que fez o Ibovespa subir mais de 30% em reai...</td>\n",
       "      <td>https://www.infomoney.com.br/mercados/ibovespa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-12-30 18:53:07</td>\n",
       "      <td>Ibovespa encerra ano em alta e sobe 34% em 202...</td>\n",
       "      <td>https://www.infomoney.com.br/mercados/ibovespa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-30 18:39:39</td>\n",
       "      <td>4 ações saltam mais de 100% em 2025: confira o...</td>\n",
       "      <td>https://www.infomoney.com.br/mercados/4-acoes-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>2025-12-30 18:39:32</td>\n",
       "      <td>5 ações caem mais de 30% em 2025; confira os d...</td>\n",
       "      <td>https://www.infomoney.com.br/mercados/5-acoes-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date                                              title  \\\n",
       "2167  2025-12-30 19:14:13  Ouro fecha ano com alta de 65,24%; Ibovespa é ...   \n",
       "0     2025-12-30 19:03:37  O que fez o Ibovespa subir mais de 30% em reai...   \n",
       "1     2025-12-30 18:53:07  Ibovespa encerra ano em alta e sobe 34% em 202...   \n",
       "2     2025-12-30 18:39:39  4 ações saltam mais de 100% em 2025: confira o...   \n",
       "2172  2025-12-30 18:39:32  5 ações caem mais de 30% em 2025; confira os d...   \n",
       "\n",
       "                                                   link  \n",
       "2167  https://www.infomoney.com.br/mercados/ouro-fec...  \n",
       "0     https://www.infomoney.com.br/mercados/ibovespa...  \n",
       "1     https://www.infomoney.com.br/mercados/ibovespa...  \n",
       "2     https://www.infomoney.com.br/mercados/4-acoes-...  \n",
       "2172  https://www.infomoney.com.br/mercados/5-acoes-...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. Execução da Coleta (Se necessário) ---\n",
    "# Descomente as linhas abaixo para coletar novos dados da API\n",
    "# for term in SEARCH_TERMS:\n",
    "#    print(f\"Processando termo: {term}\")\n",
    "#    get_news_from_period(term, START_DATE, END_DATE)\n",
    "\n",
    "# --- 2. Consolidação e Filtragem ---\n",
    "print(\"\\n\" + \"=\"*50 + \"\\nIniciando Consolidação e Filtragem...\\n\" + \"=\"*50)\n",
    "\n",
    "# Lista de palavras-chave para filtragem\n",
    "KEYWORDS = [\n",
    "    \"Ibovespa\", \"BOVA11\", \"Bolsa\", \"Ações\", \"Mercado\", \"Câmbio\", \"Dólar\", \"Juros\", \"Selic\", \"Inflação\",\n",
    "    \"IPCA\", \"Banco Central\", \"Copom\", \"Fazenda\", \"CDI\", \"Petrobras\", \"Vale\", \"Itaú\", \"Bradesco\", \"Banco do Brasil\",\n",
    "    \"B3\", \"Ambev\", \"Eletrobras\", \"WEG\", \"Suzano\", \"Gerdau\", \"Localiza\", \"Rumo\", \"Equatorial\", \"BTG Pactual\"\n",
    "]\n",
    "\n",
    "all_files = glob.glob(os.path.join(OUTPUT_DIR, \"news_*.csv\"))\n",
    "\n",
    "if all_files:\n",
    "    print(f\"Encontrados {len(all_files)} arquivos para consolidar.\")\n",
    "    \n",
    "    # Read and concatenate all files\n",
    "    df_list = [pd.read_csv(f) for f in all_files]\n",
    "    consolidated_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    total_rows = len(consolidated_df)\n",
    "    print(f\"Total de linhas antes da desduplicação e filtragem: {total_rows}\")\n",
    "    \n",
    "    # Drop duplicates based on 'link'\n",
    "    consolidated_df = consolidated_df.drop_duplicates(subset=['link'])\n",
    "    unique_rows = len(consolidated_df)\n",
    "    print(f\"Total únicos após desduplicação: {unique_rows}\")\n",
    "    \n",
    "    # --- FILTRAGEM ---\n",
    "    print(f\"\\nAplicando filtro com {len(KEYWORDS)} palavras-chave...\")\n",
    "    pattern = '|'.join([fr'\\b{k}\\b' for k in KEYWORDS]) # Adicionado \\b para garantir palavra exata (evita 'privatiz-ações')\n",
    "    # Converter para string e lidar com NaN antes de filtrar\n",
    "    mask = consolidated_df['title'].astype(str).str.contains(pattern, case=False, na=False)\n",
    "    filtered_df = consolidated_df[mask].copy()\n",
    "    \n",
    "    print(f\"Total de notícias após filtragem: {len(filtered_df)}\")\n",
    "    print(f\"Notícias removidas: {unique_rows - len(filtered_df)}\")\n",
    "\n",
    "    # Sort by date\n",
    "    if 'date' in filtered_df.columns:\n",
    "        filtered_df = filtered_df.sort_values(by='date', ascending=False)\n",
    "    \n",
    "    # Save consolidated file\n",
    "    timestamp = datetime.now().strftime('%Y%m%d')\n",
    "    # Save to parent directory of OUTPUT_DIR (dataset/infomoney)\n",
    "    parent_dir = os.path.dirname(OUTPUT_DIR)\n",
    "    output_file = os.path.join(parent_dir, f\"consolidated_news_{timestamp}.csv\")\n",
    "    filtered_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\n[SUCESSO] Arquivo consolidado e filtrado salvo em: {output_file}\")\n",
    "    display(filtered_df.head())\n",
    "else:\n",
    "    print(\"Nenhum arquivo CSV encontrado na pasta de resultados para consolidar.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
